{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba5ffbd-9984-4067-86d9-20594769b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google CloudNotebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf20285-d9ed-4b84-9628-85d170c2ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install {USER_FLAG} --upgrade transformers\n",
    "!pip -q install {USER_FLAG} --upgrade datasets\n",
    "!pip -q install {USER_FLAG} --upgrade tqdm\n",
    "!pip -q install {USER_FLAG} --upgrade cloudml-hypertune\n",
    "!pip -q install {USER_FLAG} --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dabe63-b0f5-4ada-b83a-2e11b89023f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9994ee34-4d86-4615-b4ac-f0f70be65c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  awesome-ridge-333421\n",
      "Please set your project id before proceeding to next step. Currently it's set as awesome-ridge-333421\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"awesome-ridge-333421\"  # <---CHANGE THIS TO YOUR PROJECT\n",
    "\n",
    "import os\n",
    "\n",
    "# Get your Google Cloud project ID using google.auth\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    import google.auth\n",
    "\n",
    "    _, PROJECT_ID = google.auth.default()\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "\n",
    "# validate PROJECT_ID\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"awesome-ridge-333421\":\n",
    "    print(\n",
    "        f\"Please set your project id before proceeding to next step. Currently it's set as {PROJECT_ID}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bbc9c7-9379-43c5-88e8-1c219ccefaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP = 20211204165919\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "\n",
    "TIMESTAMP = get_timestamp()\n",
    "print(f\"TIMESTAMP = {TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309cfd3e-0777-4b5d-935f-bb6bcaa6ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If you are running this notebook in Colab, run this cell and follow the\n",
    "# instructions to authenticate your GCP account. This provides access to your\n",
    "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
    "# requests.\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# If on Google Cloud Notebooks, then don't execute this code\n",
    "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        from google.colab import auth as google_auth\n",
    "\n",
    "        google_auth.authenticate_user()\n",
    "\n",
    "    # If you are running this notebook locally, replace the string below with the\n",
    "    # path to your service account key and run this cell to authenticate your GCP\n",
    "    # account.\n",
    "    elif not os.getenv(\"IS_TESTING\"):\n",
    "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b841abe6-0d27-4008-8245-b877d8332fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID = awesome-ridge-333421\n",
      "BUCKET_NAME = gs://story-gen2\n",
      "REGION = us-central1\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"gs://story-gen2\"  # <---CHANGE THIS TO YOUR BUCKET\n",
    "REGION = \"us-central1\"\n",
    "print(f\"PROJECT_ID = {PROJECT_ID}\")\n",
    "print(f\"BUCKET_NAME = {BUCKET_NAME}\")\n",
    "print(f\"REGION = {REGION}\")\n",
    "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/training/pytorch-xla.1-7:latest\"\n",
    ")\n",
    "deploy_image=(\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-xla.1-9:latest\")\n",
    "PYTHON_PACKAGE_APPLICATION_DIR = \"python_package\"\n",
    "\n",
    "source_package_file_name = f\"{PYTHON_PACKAGE_APPLICATION_DIR}/dist/trainer-0.1.tar.gz\"\n",
    "python_package_gcs_uri = (\n",
    "    f\"{BUCKET_NAME}/story2/python_package/dist/trainer-0.1.tar.gz\"\n",
    ")\n",
    "python_module_name = \"trainer.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7428716e-9541-49dd-9f0b-eea3a26e14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4355  2021-12-03T07:15:54Z  gs://story-gen2/story2/python_package/dist/trainer-0.1.tar.gz\n",
      "TOTAL: 1 objects, 4355 bytes (4.25 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l {python_package_gcs_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcf39a5-5066-4ddf-966f-44061c76f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://story-gen2/story2/custom_trainer/Dockerfile...\n",
      "Copying gs://story-gen2/story2/custom_trainer/scripts/train-cloud.sh...         \n",
      "/ [2 files][  2.9 KiB/  2.9 KiB]                                                \n",
      "Operation completed over 2 objects/2.9 KiB.                                      \n",
      "Copying gs://story-gen2/story2/python_package/dist/trainer-0.1.tar.gz...\n",
      "Copying gs://story-gen2/story2/python_package/scripts/train-cloud.sh...         \n",
      "Copying gs://story-gen2/story2/python_package/setup.py...                       \n",
      "Copying gs://story-gen2/story2/python_package/trainer.egg-info/PKG-INFO...      \n",
      "/ [4 files][  7.1 KiB/  7.1 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://story-gen2/story2/python_package/trainer.egg-info/SOURCES.txt...\n",
      "Copying gs://story-gen2/story2/python_package/trainer.egg-info/dependency_links.txt...\n",
      "Copying gs://story-gen2/story2/python_package/trainer.egg-info/requires.txt...  \n",
      "Copying gs://story-gen2/story2/python_package/trainer.egg-info/top_level.txt... \n",
      "Copying gs://story-gen2/story2/python_package/trainer/__init__.py...            \n",
      "Copying gs://story-gen2/story2/python_package/trainer/experiment.py...          \n",
      "Copying gs://story-gen2/story2/python_package/trainer/metadata.py...            \n",
      "Copying gs://story-gen2/story2/python_package/trainer/model.py...               \n",
      "Copying gs://story-gen2/story2/python_package/trainer/task.py...                \n",
      "Copying gs://story-gen2/story2/python_package/trainer/utils.py...               \n",
      "- [14 files][ 17.9 KiB/ 17.9 KiB]                                               \n",
      "Operation completed over 14 objects/17.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://story-gen2/story2/custom_trainer ./\n",
    "!gsutil cp -r gs://story-gen2/story2/python_package ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e983d11a-995a-4a99-ab6d-2ad64a5d2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adam_epsilon=1e-08, batch_size=4, job_dir='gs://output-story/models/story-gen', learning_rate=1e-05, model_name='story-gen', num_epochs=1, warmup=0.1, weight_decay=0.01)\n",
      "loading data\n",
      "Downloading: 100%|█████████████████████████| 0.99M/0.99M [00:00<00:00, 4.89MB/s]\n",
      "Downloading: 100%|███████████████████████████| 446k/446k [00:00<00:00, 2.78MB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.29M/1.29M [00:00<00:00, 6.66MB/s]\n",
      "Downloading: 100%|██████████████████████████████| 665/665 [00:00<00:00, 371kB/s]\n",
      "loading data completed\n",
      "Downloading: 100%|███████████████████████████| 523M/523M [00:07<00:00, 70.0MB/s]\n",
      "***** Running training *****\n",
      "  Num examples = 12\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:50<00:00, 16.71s/it]***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 4\n",
      "\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 67%|██████████████████████████████               | 2/3 [00:04<00:02,  2.47s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 3.6459648609161377, 'eval_runtime': 14.8224, 'eval_samples_per_second': 0.81, 'eval_steps_per_second': 0.202, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████████| 3/3 [01:05<00:00, 16.71s/it]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:09<00:00,  3.50s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 65.5343, 'train_samples_per_second': 0.183, 'train_steps_per_second': 0.046, 'train_loss': 4.08456293741862, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████████| 3/3 [01:05<00:00, 21.84s/it]\n",
      "Saving model checkpoint to /tmp/story-gen\n",
      "Configuration saved in /tmp/story-gen/config.json\n",
      "Model weights saved in /tmp/story-gen/pytorch_model.bin\n",
      "Saved model files in gs://output-story/models/story-gen/story-gen\n"
     ]
    }
   ],
   "source": [
    "!cd {PYTHON_PACKAGE_APPLICATION_DIR} && python3 -m trainer.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd131f95-ac38-4638-a1fb-0b8c892b09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/training/pytorch-xla.1-7:latest\n",
      "python_package_gcs_uri=gs://story-gen2/story2/python_package/dist/trainer-0.1.tar.gz\n",
      "python_module_name=trainer.task\n",
      "JOB_NAME=story-gen-pytorch-pkg-ar-20211204165936\n",
      "JOB_NAME=story-gen-20211204165936\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "print(\n",
    "    f\"PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI={PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI}\"\n",
    ")\n",
    "print(f\"python_package_gcs_uri={python_package_gcs_uri}\")\n",
    "print(f\"python_module_name={python_module_name}\")\n",
    "JOB_NAME = f\"story-gen-pytorch-pkg-ar-{get_timestamp()}\"\n",
    "DISPLAY_NAME=f\"story-gen-{get_timestamp()}\"\n",
    "print(f\"JOB_NAME={JOB_NAME}\")\n",
    "print(f\"JOB_NAME={DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a27923-d6d3-4a51-8181-313ab466a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION,staging_bucket='output-story')\n",
    "job = aiplatform.CustomPythonPackageTrainingJob(\n",
    "    display_name=f\"{JOB_NAME}\",\n",
    "    python_package_gcs_uri=python_package_gcs_uri,\n",
    "    python_module_name=python_module_name,\n",
    "    container_uri=PRE_BUILT_TRAINING_CONTAINER_IMAGE_URI,\n",
    "    model_serving_container_image_uri=deploy_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30759653-1406-4fa4-a16e-8e57a44d7544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n",
      "gs://output-story/models/story-gen \n",
      "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4218783234823028736?project=60899115109\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/60899115109/locations/us-central1/trainingPipelines/4218783234823028736 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5465822934767501312?project=60899115109\n",
      "INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/60899115109/locations/us-central1/trainingPipelines/4218783234823028736 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "training_args = [\"--num_epochs\", \"1\", \"--model_name\", \"story-gen\",\"--job_dir\",\"/output-story/models\"]\n",
    "\n",
    "model = job.run(\n",
    "    model_display_name=DISPLAY_NAME,\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    args=training_args,\n",
    "    base_output_dir=f'gs://output-story/models/story-gen',\n",
    "    sync=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ae07ae6-9447-449e-b689-772f8ac6f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./predictor/custom_text_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./predictor/custom_text_handler.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MyHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    The handler takes an input string and returns the classification text \n",
    "    based on the serialized transformers checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self,ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"    \n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_pt_path):\n",
    "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
    "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "        # Load model\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "        print('loading model and tokenizer')\n",
    "        # Ensure to use the same tokenizer used during training\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\" Preprocessing input request by tokenizing\n",
    "            Extend with your own preprocessing steps as needed\n",
    "        \"\"\"\n",
    "        print(\"preprocess\")\n",
    "        text = data[0].get(\"data\")\n",
    "        if text is None:\n",
    "            text = data[0].get(\"body\")\n",
    "        print(\"text is\",text)\n",
    "        s = text.decode('utf-8')\n",
    "        logger.info(\"Received text: '%s'\", s)\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        tokenizer.pad_token=tokenizer.eos_token\n",
    "        # Tokenize the texts\n",
    "        for p in '!,.:;?':\n",
    "            s=s.replace(' '+p,p)\n",
    "            s=s.replace(' '+'n\\'t','n\\'t')\n",
    "            s=s.replace(' '+'\\'s','\\'s')\n",
    "            s=s.replace(' '+'\\'re','\\'re')\n",
    "            s=s.replace(' '+'\\'ve','\\'ve')\n",
    "            s=s.replace(' '+'\\'ll','\\'ll')\n",
    "            s=s.replace(' '+'\\'am','\\'am')\n",
    "            s=s.replace(' '+'\\'m','\\'m')\n",
    "            s=s.replace(' '+'\\' m','\\'m')\n",
    "            s=s.replace(' '+'\\'m','\\'m')\n",
    "            s=s.replace(' '+'\\' ve','\\'ve')\n",
    "            s=s.replace(' '+'\\' s','\\'s')\n",
    "            s=s.replace('<newline>','\\n')\n",
    "        \n",
    "        t=list(s)\n",
    "        logger.info(\"sentence: '%s'\",s)\n",
    "        tokenizer_args = ((s,))\n",
    "        logger.info(\"tokenizer args: %s\", *tokenizer_args)\n",
    "        encoded_prompt = tokenizer.encode(*tokenizer_args, add_special_tokens=False, return_tensors=\"pt\")\n",
    "        print(\"preprocess done\")\n",
    "        print(encoded_prompt)\n",
    "        return encoded_prompt\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\" Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        print('inference')\n",
    "        print(inputs)\n",
    "        output_sequences = self.model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_length=300,\n",
    "        temperature=1,\n",
    "        top_k=0,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=3\n",
    "        )\n",
    "        if len(output_sequences.shape) > 2:\n",
    "            output_sequences.squeeze_()\n",
    "        texts=[]\n",
    "        print('inference end')\n",
    "        for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "            print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
    "            generated_sequence = generated_sequence.tolist()\n",
    "            # Decode text\n",
    "            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            tokenizer.pad_token=tokenizer.eos_token\n",
    "            text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "            # Remove all text after eos token\n",
    "            text = text[: text.find(tokenizer.eos_token)]\n",
    "            texts.append(text)\n",
    "            print(text)\n",
    "        \n",
    "        return [texts]\n",
    "        \n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        print('post')\n",
    "        return inference_output\n",
    "    # def handle(self, data, ctx):\n",
    "    #     model_input = self.preprocess(data)\n",
    "    #     model_output = self.inference(model_input)\n",
    "    #     return self.postprocess(model_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e6fcff3-6b32-433b-a605-8c3fcf74a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM_PREDICTOR_IMAGE_URI = gcr.io/awesome-ridge-333421/pytorch_predict_story-gen\n",
      "Copying gs://output-story/models/story-gen/story-gen/config.json...\n",
      "Copying gs://output-story/models/story-gen/story-gen/pytorch_model.bin...       \n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "Copying gs://output-story/models/story-gen/story-gen/training_args.bin...       \n",
      "| [3 files][486.8 MiB/486.8 MiB]                                                \n",
      "Operation completed over 3 objects/486.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "GCS_MODEL_ARTIFACTS_URI = \"gs://output-story/models/story-gen/story-gen\"\n",
    "APP_NAME='story-gen'\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")\n",
    "!gsutil cp -r $GCS_MODEL_ARTIFACTS_URI ./predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5724104c-ecc5-4285-934d-08e66db49e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./predictor/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest\n",
    "\n",
    "# install dependencies\n",
    "RUN pip3 install transformers\n",
    "# RUN git clone https://github.com/pytorch/serve.git\n",
    "# RUN pip3 install torchserve torch-model-archiver torch-workflow-archiver\n",
    "RUN pip3 install torch torchvision torchserve torch-model-archiver -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# copy model artifacts, custom handler and other dependencies\n",
    "# RUN pwd\n",
    "# RUN ls -lart /home\n",
    "COPY ./custom_text_handler.py /home/model-server/\n",
    "COPY ./story-gen/ /home/model-server/\n",
    "\n",
    "# create torchserve configuration file\n",
    "USER root\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:9000\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:9001\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmetrics_address=http://0.0.0.0:9002\" >> /home/model-server/config.properties\n",
    "# RUN printf \"\\ninstall_py_dep_per_model=true\" >> /home/model-server/config.properties\n",
    "\n",
    "USER model-server\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 9000\n",
    "EXPOSE 9001\n",
    "\n",
    "# create model archive file packaging model artifacts and dependencies\n",
    "RUN torch-model-archiver -f \\\n",
    "  --model-name=$APP_NAME \\\n",
    "  --version=1.0 \\\n",
    "  --serialized-file=/home/model-server/pytorch_model.bin \\\n",
    "  --handler=/home/model-server/custom_text_handler.py \\\n",
    "  --extra-files \"/home/model-server/config.json,/home/model-server/training_args.bin\" \\\n",
    "  --export-path=/home/model-server/model-store\n",
    "\n",
    "# run Torchserve HTTP serve to respond to prediction requests\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ncs\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server/model-store\"]\n",
    "\n",
    "EOF\n",
    "\n",
    "echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8343df5f-0166-41d4-98ff-f3a7ddc5f06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  1.021GB\n",
      "Step 1/15 : FROM pytorch/torchserve:latest\n",
      " ---> 84cd5f2ee48d\n",
      "Step 2/15 : RUN pip3 install transformers\n",
      " ---> Using cache\n",
      " ---> 621300b0465a\n",
      "Step 3/15 : RUN pip3 install torch torchvision torchserve torch-model-archiver -f https://download.pytorch.org/whl/torch_stable.html\n",
      " ---> Using cache\n",
      " ---> 85a79afe2649\n",
      "Step 4/15 : COPY ./custom_text_handler.py /home/model-server/\n",
      " ---> cdc1e620d391\n",
      "Step 5/15 : COPY ./story-gen/ /home/model-server/\n",
      " ---> a8eaa31566c9\n",
      "Step 6/15 : USER root\n",
      " ---> Running in 91eff801029b\n",
      "Removing intermediate container 91eff801029b\n",
      " ---> 66002ae053f8\n",
      "Step 7/15 : RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
      " ---> Running in e55116755760\n",
      "Removing intermediate container e55116755760\n",
      " ---> 8514e9bf4755\n",
      "Step 8/15 : RUN printf \"\\ninference_address=http://0.0.0.0:9000\" >> /home/model-server/config.properties\n",
      " ---> Running in 0b8c2502f043\n",
      "Removing intermediate container 0b8c2502f043\n",
      " ---> a8118ef768c4\n",
      "Step 9/15 : RUN printf \"\\nmanagement_address=http://0.0.0.0:9001\" >> /home/model-server/config.properties\n",
      " ---> Running in cbced8f144ce\n",
      "Removing intermediate container cbced8f144ce\n",
      " ---> a4af222f9791\n",
      "Step 10/15 : RUN printf \"\\nmetrics_address=http://0.0.0.0:9002\" >> /home/model-server/config.properties\n",
      " ---> Running in 89f1ad5dfef4\n",
      "Removing intermediate container 89f1ad5dfef4\n",
      " ---> a3884fec8b30\n",
      "Step 11/15 : USER model-server\n",
      " ---> Running in 1ecb0c12ce00\n",
      "Removing intermediate container 1ecb0c12ce00\n",
      " ---> bb41172cd165\n",
      "Step 12/15 : EXPOSE 9000\n",
      " ---> Running in d813fc5c5bd6\n",
      "Removing intermediate container d813fc5c5bd6\n",
      " ---> 919014e3fab1\n",
      "Step 13/15 : EXPOSE 9001\n",
      " ---> Running in 07334ac7c774\n",
      "Removing intermediate container 07334ac7c774\n",
      " ---> ad72c2c30394\n",
      "Step 14/15 : RUN torch-model-archiver -f   --model-name=story-gen   --version=1.0   --serialized-file=/home/model-server/pytorch_model.bin   --handler=/home/model-server/custom_text_handler.py   --extra-files \"/home/model-server/config.json,/home/model-server/training_args.bin\"   --export-path=/home/model-server/model-store\n",
      " ---> Running in 88387677edfb\n",
      "Removing intermediate container 88387677edfb\n",
      " ---> 72dc912417aa\n",
      "Step 15/15 : CMD [\"torchserve\",      \"--start\",      \"--ncs\",      \"--ts-config=/home/model-server/config.properties\",      \"--models\",      \"story-gen=story-gen.mar\",      \"--model-store\",      \"/home/model-server/model-store\"]\n",
      " ---> Running in f52c3a578c6a\n",
      "Removing intermediate container f52c3a578c6a\n",
      " ---> d18c95a2ec87\n",
      "Successfully built d18c95a2ec87\n",
      "Successfully tagged gcr.io/awesome-ridge-333421/pytorch_predict_story-gen:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build \\\n",
    "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "  ./predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd978134-a46d-4f62-aa89-852babefc3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story\n",
      "1d65f5f16a0bab3106ddeb6728abca5df6fb04c4a4162cf996d67d5f2e5c43a5\n"
     ]
    }
   ],
   "source": [
    "!docker stop story\n",
    "!docker run -t -d --rm -p 9000:9000 --name=story $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "!sleep 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17ffa71b-d298-4f43-ab54-11798dcc1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"Healthy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9000/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "474a9d25-bea2-4ea2-966a-7e697191df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [[\"Childrens logic dictates the way the world works.\\n\\nWas there any sort of intentionally faked story to tease the audience at age 12, but the boys sure looked like they belonged in the movies. Suddenly, a kid woke up one morning, pushed a baby out of the little dirt and let her ride down the same section of street, crying out and claiming, \\\"I'm little.\\\"\\n\\nThat certainly wasn't the only time the voice in the corner of his mind shouted out: \\\"Where's the chicken?\\\" His roommate had a pet cat when she was 11. But eventually, after the gentle pet calmed him down, she told him she heard her older sister crying and stomping over some nearby trees, thinking: \\\"I was crying! I'm fucking making my grandpa cry!\\\"\\n\\nWithout a break, he left his couch and walked to the driveway. It was around 3:30 p.m. When he returned to school, he saw the little cat not at school, but at a place the guys loved: a dusty place in front of one of the shiny, white-on-a-car windows. He figured he would just let his parents know about the cat's story. He'd like the parents to believe that he was being petrified. They had been curious about the Little Cat in a Google Map, but he thought there might be something strange happening to it. His parents were very excited about having the cat when he was 11, but he wanted t\", \"Childrens logic dictates the way the world works.\\n\\nHow much do children sleep when they're not working?\\n\\nWhen the family has free time, children must spend a whole day in bed.\\n\\nThey must eat at least 40 times a day, usually 7 or 8, every night and every morning.\\n\\nThey must be awake to most of the morning's work, but not all of the day.\\n\\nResearch suggests the body's total hours of sleep is lower than mothers' hours.\\n\\nThe amount of time children spend deprived of their sleep, with the longest lasting effect being those spent in public (while their mothers are asleep).\\n\\nIt's common to see bright kids with low-grade emotional problems but poor-grade middle schoolers.\\n\\nChildren who don't sleep are missing out on important social activities like ballet lessons.\\n\\nWhile children don't become perfectly suited for sports or TV play, they are surrounded by their family who raise them.\\n\\nThey are also left in need of support from parents in need.\\n\\nSome people might say that toddlers who can sleep just aren't good at arithmetic or arithmetic problems.\\n\\nBut in science and psychology, the key is for children to be taught an active discipline, one that can help them navigate the family and navigate their friendships.\\n\\nLook out for those old ladies. Don't force them to do anything. This might well result in them staying home.\\n\\nAn elderly parent migh\", \"Childrens logic dictates the way the world works.\\n\\nFrom tasks and levels, from keys and stages, a question pops up. It often involves 'what is it about?' or 'does the activity feel like playing music' as well as 'what happens when one remembers we're standing around waiting to do something else?'\\n\\nTracking through this question is quite difficult. If you suddenly come across a trivia question about local Tasmanians, you'll have to ask a colleague: 'Is there a new rock band or choir performing in Auckland?'\\n\\nAnd if you find that kind of 'loud' instrumentation at a play on the local Tube, it's a bit tough to be the person who was making the choice.\\n\\n\\\"If you think that when you see my work, I feel that a certain style of play or idea of music is in the room, you'll hear that again and again. And I just find that increasingly difficult, because I am starting to feel that I'm missing something,\\\" Mr Wallace said.\\n\\n\\\"When we moved back to England to do music, my whole life I was going to play in a show. It wasn't until I came home in the early 2000s that I realised that I wasn't in a band and that I'm in a choir.\\n\\n\\\"At that time it was rather simple, there was nothing to play, I was playing some vocal parts, and some rhythms had been written down. And that wa\"]]}"
     ]
    }
   ],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat > ./predictor/instances.json <<END\n",
    "{ \n",
    "   \"instances\": [\n",
    "     { \n",
    "       \"data\": {\n",
    "         \"b64\": \"$(echo 'Childrens logic dictates the way the world works.' | base64 --wrap=0)\"\n",
    "       }\n",
    "     }\n",
    "   ]\n",
    "}   \n",
    "\n",
    "END\n",
    "\n",
    "curl -s -X POST \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  -d @./predictor/instances.json \\\n",
    "  http://localhost:9000/predictions/$APP_NAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e8c8776-9b22-4acd-b2f4-5ef530a63f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/awesome-ridge-333421/pytorch_predict_story-gen]\n",
      "\n",
      "\u001b[1Bdba05798: Preparing \n",
      "\u001b[1Bad5587fd: Preparing \n",
      "\u001b[1B970ea338: Preparing \n",
      "\u001b[1B6539f803: Preparing \n",
      "\u001b[1Be299204a: Preparing \n",
      "\u001b[1B1aea82dd: Preparing \n",
      "\u001b[1B07b07f5b: Preparing \n",
      "\u001b[1B0a3aa641: Preparing \n",
      "\u001b[1Bfaf96803: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B8fc6c1fc: Preparing \n",
      "\u001b[1B8846dbe4: Preparing \n",
      "\u001b[1B411b72c6: Preparing \n",
      "\u001b[1Bb1b63053: Preparing \n",
      "\u001b[10Baea82dd: Pushed   510.4MB/510.4MB\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[9A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[15A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2Klatest: digest: sha256:02e801b28d66442ead54914aa7836d90cc217a3d1edab183fd137e46f0e00625 size: 3665\n"
     ]
    }
   ],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9752f39-1502-4bde-be54-9a52d1c08283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_display_name = f\"{APP_NAME}-{get_timestamp()}\"\n",
    "model_description = \"PyTorch based story generation with custom container\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d926d982-081a-4c5e-8695-d80736949ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/60899115109/locations/us-central1/models/3240555436172115968/operations/8020228208345481216\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/60899115109/locations/us-central1/models/3240555436172115968\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/60899115109/locations/us-central1/models/3240555436172115968')\n",
      "story-gen-20211204033549\n",
      "projects/60899115109/locations/us-central1/models/3240555436172115968\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "660ba7ab-b183-4a69-a4cc-8f51a5e24002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/60899115109/locations/us-central1/endpoints/8203174779860025344/operations/9220437509039718400\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/60899115109/locations/us-central1/endpoints/8203174779860025344\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/60899115109/locations/us-central1/endpoints/8203174779860025344')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/60899115109/locations/us-central1/endpoints/8203174779860025344\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/60899115109/locations/us-central1/endpoints/8203174779860025344/operations/2282642283075469312\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/60899115109/locations/us-central1/endpoints/8203174779860025344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f0eec1fb2d0> \n",
       "resource name: projects/60899115109/locations/us-central1/endpoints/8203174779860025344"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint-{get_timestamp()}\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)\n",
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db67df5f-57d8-4a76-9182-d4cf785f204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63aa99b9-dcd4-4876-85a0-4cde65841ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint('projects/60899115109/locations/us-central1/endpoints/8203174779860025344')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb87425b-aef4-49bf-800d-afdd30e86a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [\n",
    "    b\"Childrens logic dictates the way the world works.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec77ad33-37ed-41ba-9af1-c1c0b4fe9411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Input text: \n",
      "\tChildrens logic dictates the way the world works.\n",
      "\n",
      "Formatted input: \n",
      "[\n",
      "    {\n",
      "        \"data\": {\n",
      "            \"b64\": \"Q2hpbGRyZW5zIGxvZ2ljIGRpY3RhdGVzIHRoZSB3YXkgdGhlIHdvcmxkIHdvcmtzLg==\"\n",
      "        }\n",
      "    }\n",
      "]\n",
      "\n",
      "Prediction response: \n",
      "\tPrediction(predictions=[['Childrens logic dictates the way the world works. Unrighteous kids are taught that if they fail to pay their bills, you shouldn\\'t be bothered by school officials; they have to deal with bullies in real time. I can remember seeing a line on my calendar while I was engaged in \"Forgiving Dad.\" At any given moment I watched as my family\\'s milk carton was being rammed into my face and my friends looked down at me.\\n\\nThough living in an Orthodox Christian family could have impacted how well our kids answered to this theology, the majority of the time the one that got away with failing to pay their bills eventually got in trouble. Meanwhile, when the next family, white and male, did, they simply decided to stay home and live outside the house.\\n\\nIn the classroom, many students read my Bible each day. If I asked someone \"what do you mean \\'practicing Jehovah\\'s Witnesses\\'?\" they invariably would reply, \"because I didn\\'t want to ask.\" Most Americans are in no position to publicly proclaim how God shapes their behavior.\\n\\nPart of the problem is that we don\\'t respond to adult testimonies or those of our children as individuals. Our hearts and minds often make mistakes that more often than not don\\'t relate to our lives or our kids\\' futures. When those mistakes happen, those accountable fail the tests. Without real responsibility, self-respect and conscience, our students and parents would struggle through the daily lives of poverty, hunger an', \"Childrens logic dictates the way the world works. For example, every cell within a Turing machine is thought to be a Turing machine and vice versa. We humans get us here, but most other brainy people are as well.\\n\\nWhen a scientist observes something in the echolocation graph, its interaction with many simulations around it quickly moves what has to be to unfold inside the human being as something happens to the computer in that graph. And it is certainly possible to rewire our brains (under the help of A.R.M.E.) with valuable information about what we are doing and to try to find the correct ones.\\n\\nThe cognitive machine is every bit as sophisticated as we thought it was in terms of so much data, and will be widely used in the future to predict future human behavior. It is also poised to advance once we can access such raw computing data without learning or sitting idly by in the foreground as it does in our heads.\\n\\nAnd the trick? Too much data can break its rules, so this next iteration of the brain will have great opportunities to improve on the process by pulling it out of the machine and transmitting it to the human brain. We have already discovered that on the computer, empathy is something we really have nothing to learn about. We get to choose among sentient individuals by making decisions about their affections. But, when we show it off, our brains say they don't have an idea of what's going on\", 'Childrens logic dictates the way the world works. I thought I\\'d write it down, then shoot myself in the foot as I had ready to proceed. The comic introduces the idea that a piece of chicken that was alive with dinosaurs and eels was written to give him a breath and help him carry on his adventures. This is what happened.\\n\\nExcerpted from A Song of Twin Swords by Trine Teague, via Big Little Lies.\\n\\nA great deal has happened in my career in animation over the years, which includes Laughter, Banana Butter, Creation, They Never Knocked Me Out and motion pictures, and even sports games like Kite Runner. My absolute favorite example was Elementary School, where I wrote a jigsaw puzzle for over six hours and made the right choice by just shooting \"engine\" on all the components, or a piece of structure for a cut object, like the fallen people in Archie. You could finally come up with something like this:\\n\\nBreakfast-Breakfast sandwiches look terrific, and no one expects these new robots to never have anything new to show. I loved that section where I asked Lisa to help make it all happen. One thing that struck me as odd was that all the main characters made it to lunch, while all the toys seemed pretty dead-on to me.\\n\\nEverything seems to be going through all right, but there\\'s a long line and you\\'re eventually forced to scramble back to the day at an ou']], deployed_model_id='6214870728748040192', explanations=None)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "print(\"=\" * 100)\n",
    "for instance in test_instances:\n",
    "    print(f\"Input text: \\n\\t{instance.decode('utf-8')}\\n\")\n",
    "    b64_encoded = base64.b64encode(instance)\n",
    "    test_instance = [{\"data\": {\"b64\": f\"{str(b64_encoded.decode('utf-8'))}\"}}]\n",
    "    print(f\"Formatted input: \\n{json.dumps(test_instance, indent=4)}\\n\")\n",
    "    prediction = endpoint.predict(instances=test_instance)\n",
    "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    # for i in range(0,2):\n",
    "    #     print(f'GENERATED SEQUENCE {i+1}\\n')\n",
    "    #     print(f'{prediction[0][0][i]}\\n')\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d8de15b-dfcd-460c-bf79-2b668b689b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED SEQUENCE 1\n",
      "\n",
      "Childrens logic dictates the way the world works. Unrighteous kids are taught that if they fail to pay their bills, you shouldn't be bothered by school officials; they have to deal with bullies in real time. I can remember seeing a line on my calendar while I was engaged in \"Forgiving Dad.\" At any given moment I watched as my family's milk carton was being rammed into my face and my friends looked down at me.\n",
      "\n",
      "Though living in an Orthodox Christian family could have impacted how well our kids answered to this theology, the majority of the time the one that got away with failing to pay their bills eventually got in trouble. Meanwhile, when the next family, white and male, did, they simply decided to stay home and live outside the house.\n",
      "\n",
      "In the classroom, many students read my Bible each day. If I asked someone \"what do you mean 'practicing Jehovah's Witnesses'?\" they invariably would reply, \"because I didn't want to ask.\" Most Americans are in no position to publicly proclaim how God shapes their behavior.\n",
      "\n",
      "Part of the problem is that we don't respond to adult testimonies or those of our children as individuals. Our hearts and minds often make mistakes that more often than not don't relate to our lives or our kids' futures. When those mistakes happen, those accountable fail the tests. Without real responsibility, self-respect and conscience, our students and parents would struggle through the daily lives of poverty, hunger an\n",
      "\n",
      "GENERATED SEQUENCE 2\n",
      "\n",
      "Childrens logic dictates the way the world works. For example, every cell within a Turing machine is thought to be a Turing machine and vice versa. We humans get us here, but most other brainy people are as well.\n",
      "\n",
      "When a scientist observes something in the echolocation graph, its interaction with many simulations around it quickly moves what has to be to unfold inside the human being as something happens to the computer in that graph. And it is certainly possible to rewire our brains (under the help of A.R.M.E.) with valuable information about what we are doing and to try to find the correct ones.\n",
      "\n",
      "The cognitive machine is every bit as sophisticated as we thought it was in terms of so much data, and will be widely used in the future to predict future human behavior. It is also poised to advance once we can access such raw computing data without learning or sitting idly by in the foreground as it does in our heads.\n",
      "\n",
      "And the trick? Too much data can break its rules, so this next iteration of the brain will have great opportunities to improve on the process by pulling it out of the machine and transmitting it to the human brain. We have already discovered that on the computer, empathy is something we really have nothing to learn about. We get to choose among sentient individuals by making decisions about their affections. But, when we show it off, our brains say they don't have an idea of what's going on\n",
      "\n",
      "GENERATED SEQUENCE 3\n",
      "\n",
      "Childrens logic dictates the way the world works. I thought I'd write it down, then shoot myself in the foot as I had ready to proceed. The comic introduces the idea that a piece of chicken that was alive with dinosaurs and eels was written to give him a breath and help him carry on his adventures. This is what happened.\n",
      "\n",
      "Excerpted from A Song of Twin Swords by Trine Teague, via Big Little Lies.\n",
      "\n",
      "A great deal has happened in my career in animation over the years, which includes Laughter, Banana Butter, Creation, They Never Knocked Me Out and motion pictures, and even sports games like Kite Runner. My absolute favorite example was Elementary School, where I wrote a jigsaw puzzle for over six hours and made the right choice by just shooting \"engine\" on all the components, or a piece of structure for a cut object, like the fallen people in Archie. You could finally come up with something like this:\n",
      "\n",
      "Breakfast-Breakfast sandwiches look terrific, and no one expects these new robots to never have anything new to show. I loved that section where I asked Lisa to help make it all happen. One thing that struck me as odd was that all the main characters made it to lunch, while all the toys seemed pretty dead-on to me.\n",
      "\n",
      "Everything seems to be going through all right, but there's a long line and you're eventually forced to scramble back to the day at an ou\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print(f'GENERATED SEQUENCE {i+1}\\n')\n",
    "    print(f'{prediction[0][0][i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12291b-6fee-473f-8f0c-13c280d47ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
